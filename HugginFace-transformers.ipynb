{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "uf8q8kgh39ntqpaxtagncf",
            "metadata": {
                "cellIdentifier": "uf8q8kgh39ntqpaxtagncf",
                "vocVersion": "1.1"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Successfully loaded tokenizer and model for 'distilgpt2'.\n"
                    ]
                }
            ],
            "source": [
                "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
                "\n",
                "# Define the model name\n",
                "model_name = 'distilgpt2'\n",
                "\n",
                "# Load the tokenizer\n",
                "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
                "\n",
                "# Load the model\n",
                "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
                "\n",
                "print(f\"Successfully loaded tokenizer and model for '{model_name}'.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "yxzhbpgs5bbjsjvfoke7l",
            "metadata": {
                "cellIdentifier": "yxzhbpgs5bbjsjvfoke7l",
                "vocVersion": "1.1"
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Generated text continuations for prompt: 'AI is transforming industries by …'\n",
                        "\n",
                        "Continuation 1: AI is transforming industries by … it‥ is taking away responsibility from the people that make it possible for them to control it.․”\n",
                        "\n",
                        "This is another problem in politics. Politics and culture, the idea that people have to choose\n",
                        "\n",
                        "Continuation 2: AI is transforming industries by … increasing access to the information available, improving quality of life, enhancing the quality and accessibility of the workers’s daily lives, and the ability to work efficiently,‵­ing, creating better outcomes for workers.\n",
                        "\n",
                        "Continuation 3: AI is transforming industries by … changing the world› , the value of education, healthcare and health systems › and the importance of social change,‬ ′ which is important for all in the new world, we see it is increasing the\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "prompt = 'AI is transforming industries by …'\n",
                "\n",
                "# Encode the input prompt\n",
                "inputs = tokenizer(prompt, return_tensors='pt')\n",
                "\n",
                "# Generate text\n",
                "generated_sequences = model.generate(\n",
                "    inputs['input_ids'],\n",
                "    max_length=50,  # Limit the length of generated text\n",
                "    num_return_sequences=3, # Generate three continuations\n",
                "    do_sample=True, # Enable sampling for more varied outputs\n",
                "    top_k=50, # Consider top 50 tokens for sampling\n",
                "    top_p=0.95, # Use nucleus sampling\n",
                "    no_repeat_ngram_size=2, # Prevent repeating n-grams\n",
                "    pad_token_id=tokenizer.eos_token_id # Set pad token for DistilGPT2\n",
                ")\n",
                "\n",
                "print(f\"Generated text continuations for prompt: '{prompt}'\\n\")\n",
                "\n",
                "# Decode and print the generated sequences\n",
                "for i, seq in enumerate(generated_sequences):\n",
                "    decoded_sequence = tokenizer.decode(seq, skip_special_tokens=True)\n",
                "    print(f\"Continuation {i+1}: {decoded_sequence}\\n\")"
            ]
        }
    ],
    "metadata": {
        "kernel_id": "155d6b60-fb25-4d06-a291-772e238333ef",
        "kernelspec": {
            "display_name": ".venv (3.14.0)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.14.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
